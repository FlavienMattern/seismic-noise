{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Récupération des stations des réseaux `FR`, `RD`, et `G` disponibles pendant la période de COVID-19 débutant le **15 Février 2020**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from seismic_noise import *\n",
    "\n",
    "from obspy import UTCDateTime, read_inventory\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.clients.fdsn.client import FDSNNoDataException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération des stations du territoire métropolitain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\"RESIF\")\n",
    "tStart = \"2019-01-01\"\n",
    "tEnd = \"2020-01-01\"\n",
    "load_stations = True\n",
    "st_file = \"DATA/st_metadata/stations_fr_2019.xml\"\n",
    "st_availability = \"DATA/st_metadata/stations_fr_availability_2019.csv\"\n",
    "network = \"FR,G,RD\"\n",
    "channel = \"HHZ\"\n",
    "percent_keep = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Récupération des disponibilités via le constructeur de requêtes availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Network</th>\n",
       "      <th>Station</th>\n",
       "      <th>Location</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Quality</th>\n",
       "      <th>SampleRate</th>\n",
       "      <th>Earliest</th>\n",
       "      <th>Latest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FR</td>\n",
       "      <td>ABJF</td>\n",
       "      <td>00</td>\n",
       "      <td>HHZ</td>\n",
       "      <td>M</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2019-09-04T13:45:35.960000Z</td>\n",
       "      <td>2019-10-01T06:30:12.350000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FR</td>\n",
       "      <td>ABJF</td>\n",
       "      <td>00</td>\n",
       "      <td>HHZ</td>\n",
       "      <td>M</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2019-10-01T06:31:25.670000Z</td>\n",
       "      <td>2019-10-18T13:39:50.880000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FR</td>\n",
       "      <td>ABJF</td>\n",
       "      <td>00</td>\n",
       "      <td>HHZ</td>\n",
       "      <td>M</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2019-10-18T13:41:02.670000Z</td>\n",
       "      <td>2019-11-14T00:00:01.240000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FR</td>\n",
       "      <td>ABJF</td>\n",
       "      <td>00</td>\n",
       "      <td>HHZ</td>\n",
       "      <td>M</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2019-11-14T11:06:07.810000Z</td>\n",
       "      <td>2019-11-14T13:32:00.620000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FR</td>\n",
       "      <td>AGO</td>\n",
       "      <td>00</td>\n",
       "      <td>HHZ</td>\n",
       "      <td>M</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2019-01-01T00:00:00.000000Z</td>\n",
       "      <td>2019-01-04T06:41:59.850000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15428</th>\n",
       "      <td>RD</td>\n",
       "      <td>SAVF</td>\n",
       "      <td>--</td>\n",
       "      <td>HHZ</td>\n",
       "      <td>M</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2019-10-21T11:16:50.000000Z</td>\n",
       "      <td>2019-11-03T19:40:29.990000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15429</th>\n",
       "      <td>RD</td>\n",
       "      <td>SAVF</td>\n",
       "      <td>--</td>\n",
       "      <td>HHZ</td>\n",
       "      <td>M</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2019-11-03T19:40:40.000000Z</td>\n",
       "      <td>2019-11-17T04:04:19.990000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15430</th>\n",
       "      <td>RD</td>\n",
       "      <td>SAVF</td>\n",
       "      <td>--</td>\n",
       "      <td>HHZ</td>\n",
       "      <td>M</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2019-11-17T04:04:30.000000Z</td>\n",
       "      <td>2019-11-30T12:28:09.990000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15431</th>\n",
       "      <td>RD</td>\n",
       "      <td>SAVF</td>\n",
       "      <td>--</td>\n",
       "      <td>HHZ</td>\n",
       "      <td>M</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2019-11-30T12:28:30.000000Z</td>\n",
       "      <td>2019-12-13T20:52:09.990000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15432</th>\n",
       "      <td>RD</td>\n",
       "      <td>SAVF</td>\n",
       "      <td>--</td>\n",
       "      <td>HHZ</td>\n",
       "      <td>M</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2019-12-13T20:52:20.000000Z</td>\n",
       "      <td>2019-12-15T23:59:59.990000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15433 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      #Network Station Location Channel Quality  SampleRate  \\\n",
       "0           FR    ABJF       00     HHZ       M       100.0   \n",
       "1           FR    ABJF       00     HHZ       M       100.0   \n",
       "2           FR    ABJF       00     HHZ       M       100.0   \n",
       "3           FR    ABJF       00     HHZ       M       100.0   \n",
       "4           FR     AGO       00     HHZ       M       100.0   \n",
       "...        ...     ...      ...     ...     ...         ...   \n",
       "15428       RD    SAVF       --     HHZ       M       100.0   \n",
       "15429       RD    SAVF       --     HHZ       M       100.0   \n",
       "15430       RD    SAVF       --     HHZ       M       100.0   \n",
       "15431       RD    SAVF       --     HHZ       M       100.0   \n",
       "15432       RD    SAVF       --     HHZ       M       100.0   \n",
       "\n",
       "                          Earliest                       Latest  \n",
       "0      2019-09-04T13:45:35.960000Z  2019-10-01T06:30:12.350000Z  \n",
       "1      2019-10-01T06:31:25.670000Z  2019-10-18T13:39:50.880000Z  \n",
       "2      2019-10-18T13:41:02.670000Z  2019-11-14T00:00:01.240000Z  \n",
       "3      2019-11-14T11:06:07.810000Z  2019-11-14T13:32:00.620000Z  \n",
       "4      2019-01-01T00:00:00.000000Z  2019-01-04T06:41:59.850000Z  \n",
       "...                            ...                          ...  \n",
       "15428  2019-10-21T11:16:50.000000Z  2019-11-03T19:40:29.990000Z  \n",
       "15429  2019-11-03T19:40:40.000000Z  2019-11-17T04:04:19.990000Z  \n",
       "15430  2019-11-17T04:04:30.000000Z  2019-11-30T12:28:09.990000Z  \n",
       "15431  2019-11-30T12:28:30.000000Z  2019-12-13T20:52:09.990000Z  \n",
       "15432  2019-12-13T20:52:20.000000Z  2019-12-15T23:59:59.990000Z  \n",
       "\n",
       "[15433 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://ws.resif.fr/fdsnws/availability/1/query?\\\n",
    "network={}&channel={}&starttime={}&endtime={}&format=text&\\\n",
    "orderby=nslc_time_quality_samplerate&includerestricted=true&nodata=404\".format(network, channel, tStart, tEnd)\n",
    "urllib.request.urlretrieve(url, st_availability)\n",
    "\n",
    "data_availability = pd.read_csv(st_availability, delim_whitespace=True)\n",
    "data_availability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liste des stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_list = []\n",
    "for i in range(len(data_availability[\"#Network\"])):\n",
    "    loc_name = data_availability[\"Location\"][i]\n",
    "    #if loc_name == \"--\": loc_name=\"\"\n",
    "    st_name = \"{}.{}.{}.{}\".format(data_availability[\"#Network\"][i],data_availability[\"Station\"][i],loc_name,data_availability[\"Channel\"][i])\n",
    "    st_list.append(st_name)\n",
    "\n",
    "code = data_availability[\"Station\"]\n",
    "\n",
    "st_list_unique = []\n",
    "for x in st_list:\n",
    "    if x not in st_list_unique:\n",
    "        st_list_unique.append(x)\n",
    "st_list = st_list_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 stations initialement sélectionnées (avant de contraindre ).\n"
     ]
    }
   ],
   "source": [
    "print(len(st_list), \"stations initialement sélectionnées (avant de contraindre ).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On garde les stations avec suffisamment de jours de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_list = []\n",
    "code = []\n",
    "ndays_period = int( (UTCDateTime(tEnd)-UTCDateTime(tStart))/(3600*24) )\n",
    "\n",
    "for code_name in st_list: \n",
    "    (net_name, st_name, loc_name, cha_name) = code_name.split('.')\n",
    "    t1 = data_availability[\"Earliest\"].loc[ data_availability[\"#Network\" ] == net_name].loc[ data_availability[\"Station\" ] == st_name].loc[ data_availability[\"Location\"] == loc_name ].loc[ data_availability[\"Channel\" ] == cha_name].tolist()\n",
    "    t2 = data_availability[\"Latest\"].loc[ data_availability[\"#Network\" ] == net_name].loc[ data_availability[\"Station\" ] == st_name].loc[ data_availability[\"Location\"] == loc_name ].loc[ data_availability[\"Channel\" ] == cha_name].tolist()\n",
    "    t1 = np.asarray([UTCDateTime(t1[i]) for i in range(len(t1))])\n",
    "    t2 = np.asarray([UTCDateTime(t2[i]) for i in range(len(t2))])\n",
    "    diff = int( sum((t2-t1) / (3600*24)) )  # Nombre de jours de données dispo\n",
    "    if diff >= percent_keep*ndays_period:\n",
    "        diff_list.append(diff)\n",
    "        code.append(st_name)\n",
    "\n",
    "code_unique = []\n",
    "for x in code:\n",
    "    if x not in code_unique:\n",
    "        code_unique.append(x)\n",
    "code = \",\".join(code_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Récupération des stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tStart = UTCDateTime(tStart)\n",
    "tEnd = UTCDateTime(tEnd)\n",
    "\n",
    "if load_stations:\n",
    "    inventory = client.get_stations(network=network,\n",
    "                                    channel=channel, # Eventuellement BHZ pour l'antarctique\n",
    "                                    station=code,\n",
    "                                    level=\"channel\",\n",
    "                                    starttime=tStart, endtime=tEnd,\n",
    "                                    minlatitude=41, maxlatitude=52, minlongitude=-5, maxlongitude=10)\n",
    "    inventory = inventory.remove(network=\"FR\", station=\"STR\", location=\"10\", channel=\"HHZ\")\n",
    "    # inventory = inventory.remove(network=\"FR\", station=\"NIMR\", location=\"10\", channel=\"HHZ\")\n",
    "    inventory.write(st_file, format=\"STATIONXML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inventory created at 2021-09-29T13:41:16.000000Z\n",
       "\tCreated by: RESIF WEB SERVICE: fdsnws-station | version: 1.1.1 \n",
       "\t\t    http://ws.resif.fr/fdsnws/station/1/query?starttime=2019-01-01T00%3...\n",
       "\tSending institution: RESIF-SI (RESIF-DC)\n",
       "\tContains:\n",
       "\t\tNetworks (3):\n",
       "\t\t\tFR, G, RD\n",
       "\t\tStations (120):\n",
       "\t\t\tFR.AGO (Saint-Agoulin)\n",
       "\t\t\tFR.AJAC (Ajaccio)\n",
       "\t\t\tFR.ARBF (technopole de l'Arbois)\n",
       "\t\t\tFR.ARTF (Artigues)\n",
       "\t\t\tFR.ATE (Arette)\n",
       "\t\t\tFR.BALS (Balsièges)\n",
       "\t\t\tFR.BANN (fort de Banne)\n",
       "\t\t\tFR.BEGF (Béganne)\n",
       "\t\t\tFR.BETS (Betschdorf)\n",
       "\t\t\tFR.BLAF (Les Blancs)\n",
       "\t\t\tFR.BOUC (Bouclans)\n",
       "\t\t\tFR.BSTF (La Bastide-des-Jourdans)\n",
       "\t\t\tFR.CALF (plateau de Calern)\n",
       "\t\t\tFR.CAMF (Camaret-sur-Mer)\n",
       "\t\t\tFR.CARF (Carcanières)\n",
       "\t\t\tFR.CFF (63014, Aubière)\n",
       "\t\t\tFR.CHIF (Chizé)\n",
       "\t\t\tFR.CHMF (Charmoille)\n",
       "\t\t\tFR.CIEL (Vacanciel)\n",
       "\t\t\tFR.CLAF (montagne de la Clape)\n",
       "\t\t\tFR.COLF (Collangettes)\n",
       "\t\t\tFR.CRAS (Crastes)\n",
       "\t\t\tFR.DOU (Dourbes)\n",
       "\t\t\tFR.DUNF (Dun)\n",
       "\t\t\tFR.EILF (villa Eilenroc)\n",
       "\t\t\tFR.ENAUX (Enaux)\n",
       "\t\t\tFR.ESCA (L'Escarène)\n",
       "\t\t\tFR.FILF (Fillols)\n",
       "\t\t\tFR.FNEB (Nébias)\n",
       "\t\t\tFR.FOURG (Fourg)\n",
       "\t\t\tFR.FRNF (Fournols)\n",
       "\t\t\tFR.GENF (Génat)\n",
       "\t\t\tFR.GRN (38185, Corenc)\n",
       "\t\t\tFR.GUEF (Guéhenno)\n",
       "\t\t\tFR.HOHE (Hohengœft)\n",
       "\t\t\tFR.ILLF (Illfurth)\n",
       "\t\t\tFR.ILLK (Illkirch-Graffenstaden)\n",
       "\t\t\tFR.IRAF (les chalets d'Iraty)\n",
       "\t\t\tFR.ISO (Isola)\n",
       "\t\t\tFR.LABF (Labassère)\n",
       "\t\t\tFR.LAJAS (La Jasse)\n",
       "\t\t\tFR.LBL (Lubilhac)\n",
       "\t\t\tFR.LEMB (Lembach)\n",
       "\t\t\tFR.LEUC (Leucamp)\n",
       "\t\t\tFR.LOCF (Locquirec)\n",
       "\t\t\tFR.LOUF (Saint-Loup)\n",
       "\t\t\tFR.LRVF (La Rivière)\n",
       "\t\t\tFR.MANO (Manonville)\n",
       "\t\t\tFR.MELF (Melles)\n",
       "\t\t\tFR.MLS (Moulis)\n",
       "\t\t\tFR.MLYF (le Clot de Melly)\n",
       "\t\t\tFR.MON (Monaco)\n",
       "\t\t\tFR.MONQ (Montcuq-en-Quercy)\n",
       "\t\t\tFR.MORSI (Morsiglia)\n",
       "\t\t\tFR.MVIF (Mont-Vial)\n",
       "\t\t\tFR.NEEW (Neewiller)\n",
       "\t\t\tFR.NEUF (Neufchef)\n",
       "\t\t\tFR.OG02 (74185, Monnetier-Mornex)\n",
       "\t\t\tFR.OG35 (01080, Champdor-Corcelles)\n",
       "\t\t\tFR.OGAG (L'Argentière-la-Bessée)\n",
       "\t\t\tFR.OGCB (Combovin)\n",
       "\t\t\tFR.OGCC (col des Casset)\n",
       "\t\t\tFR.OGCN (Le Chalon)\n",
       "\t\t\tFR.OGDI (Digne-les-Bains)\n",
       "\t\t\tFR.OGGM (barrage de Grand'Maison)\n",
       "\t\t\tFR.OGLC (Le Caire)\n",
       "\t\t\tFR.OGMO (Modane)\n",
       "\t\t\tFR.OGMY (Moye)\n",
       "\t\t\tFR.OGRV (La Roche-Vineuse)\n",
       "\t\t\tFR.OGS1 (Séchilienne)\n",
       "\t\t\tFR.OGS2 (Séchilienne)\n",
       "\t\t\tFR.OGS3 (Séchilienne)\n",
       "\t\t\tFR.OGSA (station alpine)\n",
       "\t\t\tFR.OGSI (Sixt-Fer-à-Cheval)\n",
       "\t\t\tFR.OGSM (Saint-Maurice-de-Rotherens)\n",
       "\t\t\tFR.OGVG (Saint-Maurice-en-Valgodemard)\n",
       "\t\t\tFR.OLIV (pour Olivier)\n",
       "\t\t\tFR.OPS (OPS4)\n",
       "\t\t\tFR.ORDF (Ordiarp)\n",
       "\t\t\tFR.OSSF (Ossès)\n",
       "\t\t\tFR.PAND (pic de Padern)\n",
       "\t\t\tFR.PIAF (les Granges de la Pia)\n",
       "\t\t\tFR.PLDF (col de la Plantade)\n",
       "\t\t\tFR.PLEF (Pléven)\n",
       "\t\t\tFR.PLOF (Plœmeur)\n",
       "\t\t\tFR.PLYF (Puligny-Montrachet)\n",
       "\t\t\tFR.PYLO (Lourdes)\n",
       "\t\t\tFR.REYF (montagne du Rey)\n",
       "\t\t\tFR.RIVEL (mont Rivel)\n",
       "\t\t\tFR.RONF (Ronchamp)\n",
       "\t\t\tFR.RSL (Roselend)\n",
       "\t\t\tFR.RUSF (Rustrel)\n",
       "\t\t\tFR.SALF (Salau)\n",
       "\t\t\tFR.SALSA (chapelle Sainte-Anne)\n",
       "\t\t\tFR.SAOF (Saorge)\n",
       "\t\t\tFR.SAUF (Saumane-de-Vaucluse)\n",
       "\t\t\tFR.SDOF (Saint-Denis-d'Oléron)\n",
       "\t\t\tFR.SJAF (Saint-Jean-de-l'Albère)\n",
       "\t\t\tFR.SMPL (barrage de Sampolo)\n",
       "\t\t\tFR.SPIF (crête de Spivol)\n",
       "\t\t\tFR.STR (Strasbourg)\n",
       "\t\t\tFR.SURF (Saint-Ours)\n",
       "\t\t\tFR.SZBH (Soultz borehole)\n",
       "\t\t\tFR.TERF (Tercis-les-Bains)\n",
       "\t\t\tFR.TRBF (grotte de Trabuc)\n",
       "\t\t\tFR.TRIGF (Trigance)\n",
       "\t\t\tFR.TSDF (Thoiré-sur-Dinan)\n",
       "\t\t\tFR.TURF (col de Turini)\n",
       "\t\t\tFR.URDF (Urdès)\n",
       "\t\t\tFR.VALC (Valcebollère)\n",
       "\t\t\tFR.VERF (Verneugheol)\n",
       "\t\t\tFR.VIEF (Viey)\n",
       "\t\t\tFR.VOEL (Vœllerdingen)\n",
       "\t\t\tFR.WALT (Westhalten)\n",
       "\t\t\tFR.WLS (Welschbruch)\n",
       "\t\t\tFR.XAFF (88527, Xaffévillers)\n",
       "\t\t\tFR.ZELS (Zelsheim)\n",
       "\t\t\tG.SSB (Tunnel de Badole - Saint Sauveur en Rue, France)\n",
       "\t\t\tRD.ETNF (Estrennes, France)\n",
       "\t\t\tRD.SAVF (Savonnieres en Perthois, Champagne-Ardenne, France)\n",
       "\t\tChannels (165):\n",
       "\t\t\tFR.AGO.00.HHZ, FR.AJAC.00.HHZ, FR.ARBF.00.HHZ, FR.ARTF.00.HHZ, \n",
       "\t\t\tFR.ATE.00.HHZ, FR.BALS.00.HHZ, FR.BANN.00.HHZ, FR.BEGF.00.HHZ (3x)\n",
       "\t\t\tFR.BETS.00.HHZ, FR.BLAF.00.HHZ (2x), FR.BOUC.00.HHZ, \n",
       "\t\t\tFR.BSTF.00.HHZ, FR.CALF.00.HHZ (2x), FR.CAMF.00.HHZ (2x), \n",
       "\t\t\tFR.CARF.00.HHZ, FR.CFF.00.HHZ, FR.CHIF.00.HHZ (2x), FR.CHMF.00.HHZ\n",
       "\t\t\tFR.CIEL.00.HHZ, FR.CLAF.00.HHZ (2x), FR.COLF.00.HHZ, \n",
       "\t\t\tFR.CRAS.00.HHZ, FR.DOU.00.HHZ, FR.DUNF.00.HHZ, FR.EILF.00.HHZ, \n",
       "\t\t\tFR.ENAUX.00.HHZ, FR.ESCA.01.HHZ, FR.FILF.00.HHZ (2x), \n",
       "\t\t\tFR.FNEB.00.HHZ, FR.FOURG.00.HHZ, FR.FRNF.00.HHZ, FR.GENF.00.HHZ, \n",
       "\t\t\tFR.GRN.00.HHZ (2x), FR.GUEF.00.HHZ, FR.HOHE.00.HHZ (2x), \n",
       "\t\t\tFR.ILLF.00.HHZ (2x), FR.ILLK.00.HHZ, FR.IRAF.00.HHZ, FR.ISO.00.HHZ\n",
       "\t\t\tFR.LABF.00.HHZ, FR.LAJAS.00.HHZ (2x), FR.LBL.00.HHZ, \n",
       "\t\t\tFR.LEMB.00.HHZ (2x), FR.LEUC.00.HHZ, FR.LOCF.00.HHZ, FR.LOUF.00.HHZ\n",
       "\t\t\tFR.LRVF.00.HHZ, FR.MANO.00.HHZ, FR.MELF.00.HHZ, FR.MLS.00.HHZ, \n",
       "\t\t\tFR.MLYF.00.HHZ (3x), FR.MON.00.HHZ, FR.MONQ.00.HHZ, FR.MORSI.00.HHZ\n",
       "\t\t\tFR.MVIF.00.HHZ (2x), FR.NEEW.00.HHZ, FR.NEUF.00.HHZ, \n",
       "\t\t\tFR.OG02.00.HHZ (2x), FR.OG35.00.HHZ (2x), FR.OGAG.00.HHZ (2x), \n",
       "\t\t\tFR.OGCB.00.HHZ, FR.OGCC.00.HHZ, FR.OGCN.00.HHZ, FR.OGDI.00.HHZ (2x)\n",
       "\t\t\tFR.OGGM.00.HHZ, FR.OGLC.00.HHZ, FR.OGMO.00.HHZ, FR.OGMY.00.HHZ, \n",
       "\t\t\tFR.OGRV.00.HHZ, FR.OGS1.00.HHZ, FR.OGS2.00.HHZ, FR.OGS3.00.HHZ, \n",
       "\t\t\tFR.OGSA.00.HHZ, FR.OGSI.00.HHZ (2x), FR.OGSM.00.HHZ, \n",
       "\t\t\tFR.OGVG.00.HHZ (2x), FR.OLIV.00.HHZ, FR.OPS.00.HHZ, FR.ORDF.00.HHZ\n",
       "\t\t\tFR.OSSF.00.HHZ, FR.PAND.00.HHZ, FR.PIAF.00.HHZ (3x), \n",
       "\t\t\tFR.PLDF.00.HHZ, FR.PLEF.00.HHZ, FR.PLOF.00.HHZ, FR.PLYF.00.HHZ (2x)\n",
       "\t\t\tFR.PYLO.00.HHZ (2x), FR.PYLO.01.HHZ, FR.REYF.00.HHZ, \n",
       "\t\t\tFR.RIVEL.00.HHZ, FR.RONF.00.HHZ, FR.RSL.00.HHZ, FR.RUSF.01.HHZ, \n",
       "\t\t\tFR.RUSF.03.HHZ (2x), FR.RUSF.04.HHZ, FR.RUSF.05.HHZ (2x), \n",
       "\t\t\tFR.RUSF.06.HHZ, FR.RUSF.07.HHZ (2x), FR.SALF.00.HHZ, \n",
       "\t\t\tFR.SALSA.00.HHZ (2x), FR.SAOF.00.HHZ, FR.SAUF.00.HHZ (2x), \n",
       "\t\t\tFR.SDOF.00.HHZ, FR.SJAF.00.HHZ, FR.SMPL.00.HHZ, FR.SPIF.00.HHZ (2x)\n",
       "\t\t\tFR.STR.00.HHZ, FR.SURF.00.HHZ (2x), FR.SZBH.00.HHZ, \n",
       "\t\t\tFR.SZBH.02.HHZ, FR.TERF.00.HHZ (2x), FR.TERF.01.HHZ, FR.TRBF.00.HHZ\n",
       "\t\t\tFR.TRIGF.00.HHZ, FR.TSDF.00.HHZ, FR.TURF.00.HHZ, FR.URDF.00.HHZ, \n",
       "\t\t\tFR.VALC.00.HHZ, FR.VERF.00.HHZ, FR.VIEF.00.HHZ, FR.VOEL.00.HHZ (2x)\n",
       "\t\t\tFR.WALT.00.HHZ (2x), FR.WLS.00.HHZ, FR.XAFF.00.HHZ, \n",
       "\t\t\tFR.ZELS.00.HHZ (2x), G.SSB.10.HHZ, RD.ETNF..HHZ, RD.SAVF..HHZ"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inventory = read_inventory(st_file)\n",
    "inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open boundary dataset file. Only the 'crude', 'low',\n'intermediate' and 'high' resolution datasets are installed by default.\nIf you are requesting a 'full' resolution dataset, you may need to\ndownload and install those files separately\n(see the basemap README for details).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/mpl_toolkits/basemap/__init__.py\u001b[0m in \u001b[0;36m_readboundarydata\u001b[0;34m(self, name, as_polygons)\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m             \u001b[0mbdatfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasemap_datadir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m             \u001b[0mbdatmetafile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasemap_datadir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'meta_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/flavien/anaconda3/lib/python3.8/site-packages/mpl_toolkits/basemap/data/gshhs_h.dat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b8b7382803a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Définition du type de carte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m m = Basemap(llcrnrlon=lonmin,llcrnrlat=latmin,urcrnrlon=lonmax,urcrnrlat=latmax,\\\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12000000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9000000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mrsphere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6378137.00\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6356752.3142\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5520\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/mpl_toolkits/basemap/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, llcrnrlon, llcrnrlat, urcrnrlon, urcrnrlat, llcrnrx, llcrnry, urcrnrx, urcrnry, width, height, projection, resolution, area_thresh, rsphere, ellps, lat_ts, lat_1, lat_2, lat_0, lon_0, lon_1, lon_2, o_lon_p, o_lat_p, k_0, no_rot, suppress_ticks, satellite_height, boundinglat, fix_aspect, anchor, celestial, round, epsg, ax)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoastsegs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoastpolygontypes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readboundarydata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gshhs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mas_polygons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m             \u001b[0;31m# reformat for use in matplotlib.patches.Polygon.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoastpolygons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/mpl_toolkits/basemap/__init__.py\u001b[0m in \u001b[0;36m_readboundarydata\u001b[0;34m(self, name, as_polygons)\u001b[0m\n\u001b[1;32m   1234\u001b[0m             \u001b[0mbdatmetafile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasemap_datadir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'meta_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m         \u001b[0mpolygons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0mpolygon_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open boundary dataset file. Only the 'crude', 'low',\n'intermediate' and 'high' resolution datasets are installed by default.\nIf you are requesting a 'full' resolution dataset, you may need to\ndownload and install those files separately\n(see the basemap README for details)."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Récupération des informations\n",
    "lat = [ inventory.networks[j].stations[i].latitude for j in range(len(inventory.networks)) for i in range(len(inventory.networks[j].stations)) ]\n",
    "lon = [ inventory.networks[j].stations[i].longitude for j in range(len(inventory.networks)) for i in range(len(inventory.networks[j].stations)) ]\n",
    "code = list()\n",
    "for j in range(len(inventory.networks)):\n",
    "    for i in range(len(inventory.networks[j].stations)):\n",
    "        station_name = \"{}.{}.{}.{}\".format(inventory.networks[j].code,\n",
    "                                            inventory.networks[j].stations[i].code,\n",
    "                                            inventory.networks[j].stations[i].channels[0].location_code,\n",
    "                                            inventory.networks[j].stations[i].channels[0].code)\n",
    "        code = np.append(code, station_name)\n",
    "\n",
    "network = [ code_name.split(\".\")[0] for code_name in code ]\n",
    "colors = list();\n",
    "for code_name in code:\n",
    "    network = code_name.split(\".\")[0]\n",
    "    if network==\"FR\": colors.append(\"#991818\")\n",
    "    if network==\"G\" : colors.append(\"#537FB4\")\n",
    "    if network==\"RD\": colors.append(\"#499E42\")\n",
    "    \n",
    "\n",
    "# Mise en graphique\n",
    "plt.figure(figsize=(10,10))\n",
    "latmin = 41\n",
    "latmax = 52\n",
    "lonmin = -5\n",
    "lonmax = 11\n",
    "resol = \"h\"\n",
    "bar_width = 500\n",
    "bar_pos = 4\n",
    "\n",
    "# Définition du type de carte\n",
    "m = Basemap(llcrnrlon=lonmin,llcrnrlat=latmin,urcrnrlon=lonmax,urcrnrlat=latmax,\\\n",
    "            width=12000000,height=9000000,\\\n",
    "            rsphere=(6378137.00,6356752.3142), epsg=5520,\\\n",
    "            resolution=resol,area_thresh=1000.,projection='cyl',\\\n",
    "            lat_1=latmin,lat_2=lonmin,lat_0=latmax,lon_0=lonmax)\n",
    "\n",
    "m.drawcountries(linewidth=1, zorder=10)\n",
    "m.drawcoastlines(linewidth=1, zorder=10)\n",
    "parallels = np.arange(latmin, latmax,2.)\n",
    "meridians = np.arange(lonmin, lonmax,2.)\n",
    "m.drawparallels(parallels,labels=[False,True,True,False], color=\"gray\", zorder=1, linewidth=1)\n",
    "m.drawmeridians(meridians,labels=[False,True,True,False], color=\"gray\", zorder=1, linewidth=1)\n",
    "m.drawmapboundary(fill_color='#85C1E9')\n",
    "m.fillcontinents(color='tan',lake_color='lightblue')\n",
    "    \n",
    "# Positionnement dans les coins\n",
    "if   bar_pos==1: a, b, c = -0.35, +1, 95\n",
    "elif bar_pos==2: a, b, c =   0.5, -1, 95\n",
    "elif bar_pos==3: a, b, c = -0.35, +1, 8\n",
    "else           : a, b, c =  0.36, -1, 7\n",
    "\n",
    "lat_pos = np.linspace(latmin, latmax, 100)[c]\n",
    "lon_pos = a*abs(lonmax-lonmin) + b*bar_width/111.0/2.0 + 4.2e-2*lat_pos\n",
    "m.drawmapscale(lon_pos, lat_pos, lon_pos, lat_pos, bar_width, barstyle='fancy', zorder=100, yoffset=1500*abs(latmax-latmin))\n",
    "\n",
    "lon, lat  = m(lon, lat)\n",
    "m.scatter(lon, lat, s=50, marker=\"o\", zorder=20, edgecolors='black', color=colors, alpha=0.8)\n",
    "\n",
    "# Affichage de la légende\n",
    "l1 = plt.scatter([],[], s=50, edgecolors='black', alpha=0.8, color=\"#991818\")\n",
    "l2 = plt.scatter([],[], s=50, edgecolors='black', alpha=0.8, color=\"#537FB4\")\n",
    "l3 = plt.scatter([],[], s=50, edgecolors='black', alpha=0.8, color=\"#499E42\")\n",
    "\n",
    "labels = [\"FR ({})\".format(len(inventory.networks[0])),\n",
    "          \"G ({})\".format(len(inventory.networks[1])),\n",
    "          \"RD ({})\".format(len(inventory.networks[2]))]\n",
    "\n",
    "leg = plt.legend([l1, l2, l3], labels, ncol=1, frameon=True, fontsize=12,\n",
    "                 handlelength=1, loc=3, borderpad = 1, handletextpad=1,scatterpoints = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tri des stations isolées / urbaines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> On tri les différentes stations selon plusieurs critères pour les classer en tant que station **urbaines** ou **isolée**. Le tri se fait de deux facçons différentes :\n",
    "> \n",
    "> - Tri selon le niveau de bruit sur la période entre le 01/01/2020 et le 31/07/2020, en définissant un niveau de bruit seuil pour le classement\n",
    "> - Tri selon la variation du niveau de bruit pendant le premier confinement par rapport à avant le premier confinement\n",
    "> \n",
    "> On peut faire un tri manuel final pour ajuster au besoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération des stations en Antarctique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\"RESIF\")\n",
    "load_stations = False\n",
    "st_file = \"DATA/st_metadata/stations_antartctic.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_stations:\n",
    "    inventory = client.get_stations(network=\"G\",\n",
    "                                    station=\"CCD,DRV\",\n",
    "                                    location=\"00\",\n",
    "                                    channel=\"BHZ,EHZ,HHZ\", # Eventuellement BHZ pour l'antarctique\n",
    "                                    level=\"channel\")\n",
    "    inventory.write(st_file, format=\"STATIONXML\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory = read_inventory(st_file)\n",
    "inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des informations\n",
    "lat = [ inventory.networks[j].stations[i].latitude for j in range(len(inventory.networks)) for i in range(len(inventory.networks[j].stations)) ]\n",
    "lon = [ inventory.networks[j].stations[i].longitude for j in range(len(inventory.networks)) for i in range(len(inventory.networks[j].stations)) ]\n",
    "\n",
    "code = inventory.get_contents()[\"channels\"]\n",
    "code_unique = []\n",
    "for x in code:\n",
    "    # check if exists in unique_list or not\n",
    "    if x not in code_unique:\n",
    "        code_unique.append(x)\n",
    "code = code_unique\n",
    "\n",
    "# Mise en graphique\n",
    "plt.figure(figsize=(10,10))\n",
    "resol = \"h\"\n",
    "\n",
    "# Définition du type de carte\n",
    "m = Basemap(projection='spstere', boundinglat=-60, lon_0=0, resolution=resol)\n",
    "\n",
    "m.fillcontinents(color='gray',lake_color='gray')\n",
    "m.drawcountries(linewidth=1, zorder=10)\n",
    "m.drawcoastlines(linewidth=1, zorder=10)\n",
    "m.drawparallels(np.arange(-80.,81.,20.),labels=[False,False,False,False], color=\"gray\", zorder=1, linewidth=1)\n",
    "m.drawmeridians(np.arange(-180.,181.,20.),labels=[True,True,True,True], color=\"gray\", zorder=1, linewidth=1)\n",
    "m.drawmapboundary(fill_color='#85C1E9')\n",
    "m.fillcontinents(color='tan',lake_color='lightblue')    \n",
    "\n",
    "lon, lat  = m(lon, lat)\n",
    "m.scatter(lon, lat, s=50, marker=\"o\", zorder=20, edgecolors='black', color=\"#991818\")\n",
    "\n",
    "# Affichage de la légende\n",
    "l1 = plt.scatter([],[], s=50, edgecolors='black', alpha=0.8, color=\"#991818\")\n",
    "\n",
    "labels = [\"G ({})\".format(len(inventory.networks[0]))]\n",
    "\n",
    "leg = plt.legend([l1], labels, ncol=1, frameon=True, fontsize=12,\n",
    "                 handlelength=1, loc=3, borderpad = 1, handletextpad=1,scatterpoints = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
